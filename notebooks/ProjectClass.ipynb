{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59ae37e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "485eedea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-21 14:48:14.224751: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-05-21 14:48:14.224832: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import r2_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "140fbce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de datos de archivo .csv\n",
    "training = 'https://github.com/albahnsen/MIAD_ML_and_NLP/raw/main/datasets/dataTraining.zip'\n",
    "testing = 'https://github.com/albahnsen/MIAD_ML_and_NLP/raw/main/datasets/dataTesting.zip'\n",
    "\n",
    "data_training = pd.read_csv(training, encoding='UTF-8', index_col=0)\n",
    "data_testing = pd.read_csv(testing, encoding='UTF-8', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6065380b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>title</th>\n",
       "      <th>plot</th>\n",
       "      <th>genres</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3107</th>\n",
       "      <td>2003</td>\n",
       "      <td>Most</td>\n",
       "      <td>most is the story of a single father who takes...</td>\n",
       "      <td>['Short', 'Drama']</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>2008</td>\n",
       "      <td>How to Be a Serial Killer</td>\n",
       "      <td>a serial killer decides to teach the secrets o...</td>\n",
       "      <td>['Comedy', 'Crime', 'Horror']</td>\n",
       "      <td>5.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6724</th>\n",
       "      <td>1941</td>\n",
       "      <td>A Woman's Face</td>\n",
       "      <td>in sweden ,  a female blackmailer with a disfi...</td>\n",
       "      <td>['Drama', 'Film-Noir', 'Thriller']</td>\n",
       "      <td>7.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4704</th>\n",
       "      <td>1954</td>\n",
       "      <td>Executive Suite</td>\n",
       "      <td>in a friday afternoon in new york ,  the presi...</td>\n",
       "      <td>['Drama']</td>\n",
       "      <td>7.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2582</th>\n",
       "      <td>1990</td>\n",
       "      <td>Narrow Margin</td>\n",
       "      <td>in los angeles ,  the editor of a publishing h...</td>\n",
       "      <td>['Action', 'Crime', 'Thriller']</td>\n",
       "      <td>6.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      year                      title  \\\n",
       "3107  2003                       Most   \n",
       "900   2008  How to Be a Serial Killer   \n",
       "6724  1941             A Woman's Face   \n",
       "4704  1954            Executive Suite   \n",
       "2582  1990              Narrow Margin   \n",
       "\n",
       "                                                   plot  \\\n",
       "3107  most is the story of a single father who takes...   \n",
       "900   a serial killer decides to teach the secrets o...   \n",
       "6724  in sweden ,  a female blackmailer with a disfi...   \n",
       "4704  in a friday afternoon in new york ,  the presi...   \n",
       "2582  in los angeles ,  the editor of a publishing h...   \n",
       "\n",
       "                                  genres  rating  \n",
       "3107                  ['Short', 'Drama']     8.0  \n",
       "900        ['Comedy', 'Crime', 'Horror']     5.6  \n",
       "6724  ['Drama', 'Film-Noir', 'Thriller']     7.2  \n",
       "4704                           ['Drama']     7.4  \n",
       "2582     ['Action', 'Crime', 'Thriller']     6.6  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "e1552604",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FinalProject():\n",
    "    \"\"\"\n",
    "    Documment\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        training_df: pd.core.frame.DataFrame, \n",
    "        testing_df: pd.core.frame.DataFrame\n",
    "    ) -> None:\n",
    "        \n",
    "        \n",
    "        self.training_df = training_df\n",
    "        self.testing_df = testing_df\n",
    "        \n",
    "        \n",
    "    def get_plots(\n",
    "        self,\n",
    "        df: pd.core.frame.DataFrame\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Documment\n",
    "        \"\"\"\n",
    "        \n",
    "        return df[\"plot\"].values\n",
    "        \n",
    "    \n",
    "    def vectorize_x(self) -> None:\n",
    "        \"\"\"\n",
    "        Documment\n",
    "        \"\"\"\n",
    "        # Get both training and testing plots\n",
    "        self.train_plots = self.get_plots(self.training_df)\n",
    "        self.test_plots = self.get_plots(self.testing_df)\n",
    "        \n",
    "        # Fit the vectorizer\n",
    "        self.vectorizer = CountVectorizer(max_features=5000)\n",
    "        self.vectorizer.fit(self.train_plots)\n",
    "        \n",
    "        # Get the vectorized matrix\n",
    "        self.x_train_all = self.vectorizer.transform(self.train_plots)\n",
    "        self.x_test = self.vectorizer.transform(self.test_plots)\n",
    "        \n",
    "    def vectorize_y(self) -> None:\n",
    "        \"\"\"\n",
    "        Documment\n",
    "        \"\"\"\n",
    "        self.binarizer = MultiLabelBinarizer()\n",
    "        self.y = self.binarizer.fit_transform(self.training_df[\"genres\"].map(lambda x: eval(x)))\n",
    "        \n",
    "    def split_data(self) -> None:\n",
    "        \"\"\"\n",
    "        Documment\n",
    "        \"\"\"\n",
    "        \n",
    "        train_test_results = train_test_split(\n",
    "                                self.x_train_all,\n",
    "                                self.y, \n",
    "                                test_size=0.20,\n",
    "                                random_state=100\n",
    "        )\n",
    "        \n",
    "        self.x_train = train_test_results[0]\n",
    "        self.x_val = train_test_results[1]\n",
    "        self.y_train = train_test_results[2]\n",
    "        self.y_val = train_test_results[3]\n",
    "        \n",
    "        \n",
    "    def model(\n",
    "        self, \n",
    "        epochs: int,\n",
    "        patience: int, \n",
    "        learning_rate: float\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Documment\n",
    "        \"\"\"\n",
    "        stop = EarlyStopping(monitor=\"val_loss\", patience=patience)\n",
    "        adam = Adam(learning_rate = learning_rate)\n",
    "        input_dim = self.x_train.shape[1] \n",
    "        out_dim = self.y_train.shape[1]\n",
    "        \n",
    "        self.model = Sequential()\n",
    "        self.model.add(layers.Dense(250, input_dim=input_dim, activation=\"tanh\"))\n",
    "        self.model.add(layers.Dense(250, activation=\"tanh\"))\n",
    "        self.model.add(layers.Dense(250, activation=\"tanh\"))\n",
    "        self.model.add(layers.Dense(out_dim, activation=\"sigmoid\"))\n",
    "        self.model.compile(\n",
    "            loss=\"binary_crossentropy\", \n",
    "            optimizer=adam, \n",
    "            metrics=[\"accuracy\"]\n",
    "        )\n",
    "        \n",
    "        self.history = self.model.fit(\n",
    "                            self.x_train, \n",
    "                            self.y_train, \n",
    "                            epochs=epochs, \n",
    "                            verbose=True, \n",
    "                            validation_data=(\n",
    "                                self.x_val, \n",
    "                                self.y_val\n",
    "                            ),\n",
    "                            batch_size=10,\n",
    "                            callbacks=[stop]\n",
    "        )\n",
    "        \n",
    "    def predict(self) -> None:\n",
    "        \"\"\"\n",
    "        Documment\n",
    "        \"\"\"\n",
    "        self.predictions = self.model.predict(self.x_test)\n",
    "        \n",
    "    def save_predictions(\n",
    "        self,\n",
    "        path: str\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Documment\n",
    "        \"\"\"\n",
    "        cols = [\n",
    "            \"p_Action\", \"p_Adventure\", \"p_Animation\", \n",
    "            \"p_Biography\", \"p_Comedy\", \"p_Crime\", \n",
    "            \"p_Documentary\", \"p_Drama\", \"p_Family\",\n",
    "            \"p_Fantasy\", \"p_Film-Noir\", \"p_History\", \n",
    "            \"p_Horror\", \"p_Music\", \"p_Musical\", \n",
    "            \"p_Mystery\", \"p_News\", \"p_Romance\",\n",
    "            \"p_Sci-Fi\", \"p_Short\", \"p_Sport\", \n",
    "            \"p_Thriller\", \"p_War\", \"p_Western\"]\n",
    "        \n",
    "        res = pd.DataFrame(\n",
    "            self.predictions, \n",
    "            index=self.testing_df.index, \n",
    "            columns=cols\n",
    "        )\n",
    "        res.to_csv(path, index_label='ID')\n",
    "        \n",
    "    def run(\n",
    "        self,\n",
    "        epochs: int,\n",
    "        patience: int,\n",
    "        learning_rate: float,\n",
    "        path: str\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Documment\n",
    "        \"\"\"\n",
    "        self.vectorize_x()\n",
    "        self.vectorize_y()\n",
    "        self.split_data()\n",
    "        self.model(epochs, patience, learning_rate)\n",
    "        self.predict()\n",
    "        self.save_predictions(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "44df9454",
   "metadata": {},
   "outputs": [],
   "source": [
    "project = FinalProject(data_training, data_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "18eccde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = project.get_plots(data_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "e33ccea7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "90284240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "632/632 [==============================] - 6s 9ms/step - loss: 0.3296 - accuracy: 0.2114 - val_loss: 0.2826 - val_accuracy: 0.2438\n",
      "Epoch 2/30\n",
      "632/632 [==============================] - 6s 9ms/step - loss: 0.2716 - accuracy: 0.2723 - val_loss: 0.2580 - val_accuracy: 0.3015\n",
      "Epoch 3/30\n",
      "632/632 [==============================] - 6s 10ms/step - loss: 0.2360 - accuracy: 0.3545 - val_loss: 0.2323 - val_accuracy: 0.3268\n",
      "Epoch 4/30\n",
      "632/632 [==============================] - 7s 11ms/step - loss: 0.2019 - accuracy: 0.4148 - val_loss: 0.2181 - val_accuracy: 0.3483\n",
      "Epoch 5/30\n",
      "632/632 [==============================] - 6s 10ms/step - loss: 0.1758 - accuracy: 0.4514 - val_loss: 0.2136 - val_accuracy: 0.3794\n",
      "Epoch 6/30\n",
      "632/632 [==============================] - 6s 10ms/step - loss: 0.1552 - accuracy: 0.4748 - val_loss: 0.2130 - val_accuracy: 0.3502\n",
      "Epoch 7/30\n",
      "632/632 [==============================] - 6s 9ms/step - loss: 0.1379 - accuracy: 0.4808 - val_loss: 0.2161 - val_accuracy: 0.3604\n",
      "Epoch 8/30\n",
      "632/632 [==============================] - 6s 9ms/step - loss: 0.1224 - accuracy: 0.4900 - val_loss: 0.2219 - val_accuracy: 0.3553\n",
      "Epoch 9/30\n",
      "632/632 [==============================] - 6s 10ms/step - loss: 0.1089 - accuracy: 0.4983 - val_loss: 0.2303 - val_accuracy: 0.3452\n",
      "Epoch 10/30\n",
      "632/632 [==============================] - 6s 10ms/step - loss: 0.0969 - accuracy: 0.4997 - val_loss: 0.2393 - val_accuracy: 0.3458\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    project = FinalProject(data_training, data_testing)\n",
    "    project.run(30, 4, 0.00005, \"class.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70eeefe1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "a4573e2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(project.y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea109cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f2a433",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "193708d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_plots done\n",
      "get_plots done\n",
      "vectorize_x done\n",
      "vectorize_y done\n",
      "split_data done\n",
      "xgb_model fit done\n"
     ]
    }
   ],
   "source": [
    "# Import libraries and modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "class FinalProject():\n",
    "    \"\"\"Project class that predicts the genres of movies.\n",
    "\n",
    "    Recieves a dataframe with the training data and a dataframe with the\n",
    "    testing data. The dataframe must have the following columns:\n",
    "    - year: the year of the movie\n",
    "    - title: the title of the movie\n",
    "    - plot: the plot of the movie\n",
    "    - genres: the genres of the movie\n",
    "    - rating: the rating of the movie\n",
    "\n",
    "    The class has the following methods:\n",
    "    - get_plots: returns the plots of the training and testing dataframes\n",
    "    - vectorize_x: vectorizes the training and testing dataframes' plots\n",
    "    - vectorize_y: vectorizes the training dataframe's genres column\n",
    "    - split_data: splits the training dataframe into training and validation\n",
    "    - model: creates and train the model\n",
    "    - predict: predicts the genres of the testing dataframe\n",
    "    - save_predictions: saves the predictions in a csv file\n",
    "\n",
    "    Attributes:\n",
    "    - training_df: the training dataframe\n",
    "    - testing_df: the testing dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        training_df: pd.core.frame.DataFrame,\n",
    "        testing_df: pd.core.frame.DataFrame\n",
    "    ) -> None:\n",
    "\n",
    "        self.training_df = training_df\n",
    "        self.testing_df = testing_df\n",
    "\n",
    "    def get_plots(\n",
    "        self,\n",
    "        df: pd.core.frame.DataFrame\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"Returns the plots of the dataframe.\n",
    "\n",
    "        Args:\n",
    "            df: the dataframe\n",
    "\n",
    "        Returns:\n",
    "            The plots of the dataframe as a numpy array\n",
    "        \"\"\"\n",
    "        print(\"get_plots done\")\n",
    "        return df[\"plot\"].values\n",
    "\n",
    "    def vectorize_x(self) -> None:\n",
    "        \"\"\"Vectorizes the training and testing dataframes' plots.\n",
    "\n",
    "        Uses the CountVectorizer from sklearn to vectorize the plots.\n",
    "\n",
    "        Args:\n",
    "            None\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        # Get both training and testing plots\n",
    "        self.train_plots = self.get_plots(self.training_df)\n",
    "        self.test_plots = self.get_plots(self.testing_df)\n",
    "\n",
    "        # Fit the vectorizer\n",
    "        self.vectorizer = CountVectorizer(max_features=5000)\n",
    "        self.vectorizer.fit(self.train_plots)\n",
    "\n",
    "        # Get the vectorized matrix\n",
    "        self.x_train_all = self.vectorizer.transform(self.train_plots)\n",
    "        self.x_test = self.vectorizer.transform(self.test_plots)\n",
    "        print(\"vectorize_x done\")\n",
    "\n",
    "    def vectorize_y(self) -> None:\n",
    "        \"\"\"Vectorizes the training dataframe's genres column.\n",
    "\n",
    "        Uses the MultiLabelBinarizer from sklearn to vectorize the genres.\n",
    "\n",
    "        Args:\n",
    "            None\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        self.binarizer = MultiLabelBinarizer()\n",
    "        self.y = self.binarizer.fit_transform(\n",
    "            self.training_df[\"genres\"].map(lambda x: eval(x))\n",
    "        )\n",
    "        print(\"vectorize_y done\")\n",
    "\n",
    "    def split_data(self) -> None:\n",
    "        \"\"\"Splits the training dataframe into training and validation.\n",
    "\n",
    "        Uses the train_test_split from sklearn to split the training\n",
    "        dataframe into training and validation.\n",
    "\n",
    "        Args:\n",
    "            None\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        self.x_train, self.x_val, self.y_train, self.y_val = train_test_split(\n",
    "            self.x_train_all,\n",
    "            self.y,\n",
    "            test_size=0.2,\n",
    "            random_state=100\n",
    "        )\n",
    "        print(\"split_data done\")\n",
    "\n",
    "    def model(\n",
    "        self,\n",
    "        epochs: int,\n",
    "        patience: int,\n",
    "        learning_rate: float\n",
    "    ) -> None:\n",
    "        \"\"\"Creates and trains the model.\n",
    "\n",
    "        Creates a sequential model with the following layers:\n",
    "        - Input layer with 250 neurons and the shape of the vectorized\n",
    "          plots and tanh activation\n",
    "        - Dense layer with 250 neurons and tanh activation\n",
    "        - Dense layer with 250 neurons and tanh activation\n",
    "        - Dense layer as output layer with the shape of the vectorized\n",
    "          genres and sigmoid activation\n",
    "\n",
    "        Args:\n",
    "            epochs: the number of epochs\n",
    "            patience: the number of epochs without improvement before\n",
    "                the model stops training\n",
    "            learning_rate: the learning rate of the model\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        stop = EarlyStopping(monitor=\"val_loss\", patience=patience)\n",
    "        adam = Adam(learning_rate=learning_rate)\n",
    "        input_dim = self.x_train.shape[1]\n",
    "        out_dim = self.y_train.shape[1]\n",
    "\n",
    "        self.model = Sequential()\n",
    "        self.model.add(layers.Dense(\n",
    "            250,\n",
    "            input_dim=input_dim,\n",
    "            activation=\"tanh\")\n",
    "        )\n",
    "        self.model.add(layers.Dense(250, activation=\"tanh\"))\n",
    "        self.model.add(layers.Dense(250, activation=\"tanh\"))\n",
    "        self.model.add(layers.Dense(out_dim, activation=\"sigmoid\"))\n",
    "        self.model.compile(\n",
    "            loss=\"binary_crossentropy\",\n",
    "            optimizer=adam,\n",
    "            metrics=[\"accuracy\"]\n",
    "        )\n",
    "\n",
    "        self.history = self.model.fit(\n",
    "                            self.x_train,\n",
    "                            self.y_train,\n",
    "                            epochs=epochs,\n",
    "                            verbose=True,\n",
    "                            validation_data=(\n",
    "                                self.x_val,\n",
    "                                self.y_val\n",
    "                            ),\n",
    "                            batch_size=10,\n",
    "                            callbacks=[stop]\n",
    "        )\n",
    "\n",
    "    def xgb_model(self) -> None:\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        self.xgb_model = xgb.XGBClassifier(\n",
    "            n_estimators=1000,\n",
    "            learning_rate=0.05,\n",
    "            max_depth=5,\n",
    "            min_child_weight=1,\n",
    "            gamma=0,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            objective=\"binary:logistic\",\n",
    "            nthread=4,\n",
    "            scale_pos_weight=1,\n",
    "            seed=27\n",
    "        )\n",
    "        self.xgb_model.fit(self.x_train, self.y_train)\n",
    "        print(\"xgb_model fit done\")\n",
    "\n",
    "    def predict(self) -> None:\n",
    "        \"\"\" Predicts the genres of the testing dataframe.\n",
    "\n",
    "        Uses the model to predict the genres of the testing dataframe.\n",
    "\n",
    "        Args:\n",
    "            None\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        self.predictions = self.model.predict(self.x_test)\n",
    "\n",
    "    def predict_xgb(self) -> None:\n",
    "        \"\"\" Predicts the genres of the testing dataframe.\n",
    "\n",
    "        Uses the xgb model to predict the genres of the testing dataframe.\n",
    "\n",
    "        Args:\n",
    "            None\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        self.predictions = self.xgb_model.predict(self.x_test)\n",
    "\n",
    "    def save_predictions(\n",
    "        self,\n",
    "        path: str\n",
    "    ) -> None:\n",
    "        \"\"\"Saves the predictions in a csv file.\n",
    "\n",
    "        Saves the predictions in a csv file with the following columns:\n",
    "        - p_Action: the probability of the movie being Action\n",
    "        - p_Adventure: the probability of the movie being Adventure\n",
    "        - p_Animation: the probability of the movie being Animation\n",
    "        - p_Biography: the probability of the movie being Biography\n",
    "        - p_Comedy: the probability of the movie being Comedy\n",
    "        - p_Crime: the probability of the movie being Crime\n",
    "        - p_Documentary: the probability of the movie being Documentary\n",
    "        - p_Drama: the probability of the movie being Drama\n",
    "        - p_Family: the probability of the movie being Family\n",
    "        - p_Fantasy: the probability of the movie being Fantasy\n",
    "        - p_FilmNoir: the probability of the movie being FilmNoir\n",
    "        - p_History: the probability of the movie being History\n",
    "        - p_Horror: the probability of the movie being Horror\n",
    "        - p_Music: the probability of the movie being Music\n",
    "        - p_Musical: the probability of the movie being Musical\n",
    "        - p_Mystery: the probability of the movie being Mystery\n",
    "        - p_News: the probability of the movie being News\n",
    "        - p_Romance: the probability of the movie being Romance\n",
    "        - p_SciFi: the probability of the movie being SciFi\n",
    "        - p_Sport: the probability of the movie being Sport\n",
    "        - p_Sport: the probability of the movie being Thriller\n",
    "        - p_Thriller: the probability of the movie being Thriller\n",
    "        - p_War: the probability of the movie being War\n",
    "        - p_Western: the probability of the movie being Western\n",
    "\n",
    "        Args:\n",
    "            path: the path to the csv file to save the predictions\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        cols = [\n",
    "            \"p_Action\", \"p_Adventure\", \"p_Animation\",\n",
    "            \"p_Biography\", \"p_Comedy\", \"p_Crime\",\n",
    "            \"p_Documentary\", \"p_Drama\", \"p_Family\",\n",
    "            \"p_Fantasy\", \"p_Film-Noir\", \"p_History\",\n",
    "            \"p_Horror\", \"p_Music\", \"p_Musical\",\n",
    "            \"p_Mystery\", \"p_News\", \"p_Romance\",\n",
    "            \"p_Sci-Fi\", \"p_Short\", \"p_Sport\",\n",
    "            \"p_Thriller\", \"p_War\", \"p_Western\"]\n",
    "\n",
    "        res = pd.DataFrame(\n",
    "            self.predictions,\n",
    "            index=self.testing_df.index,\n",
    "            columns=cols\n",
    "        )\n",
    "        res.to_csv(path, index_label='ID')\n",
    "\n",
    "    def run(\n",
    "        self,\n",
    "        epochs: int,\n",
    "        patience: int,\n",
    "        learning_rate: float,\n",
    "        path: str\n",
    "    ) -> None:\n",
    "        \"\"\"Runs the entire pipeline.\n",
    "\n",
    "        Runs each of the functions in the pipeline.\n",
    "        The functions are:\n",
    "        - vectorize_x: vectorizes the training dataframe's plots column\n",
    "        - vectorize_y: vectorizes the training dataframe's genres column\n",
    "        - split_data: splits the dataframe into training and validation\n",
    "        - model: creates and trains the model\n",
    "        - predict: predicts the genres of the testing dataframe\n",
    "        - save_predictions: saves the predictions in a csv file\n",
    "        \"\"\"\n",
    "        self.vectorize_x()\n",
    "        self.vectorize_y()\n",
    "        self.split_data()\n",
    "        self.xgb_model()\n",
    "        self.predict_xgb()\n",
    "        # self.model(epochs, patience, learning_rate)\n",
    "        # self.predict()\n",
    "        self.save_predictions(path)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Get the data from the csv file and store it in a dataframe\n",
    "    path = \"https://github.com/albahnsen/MIAD_ML_and_NLP/raw/main/datasets/\"\n",
    "    training = path + \"dataTraining.zip\"\n",
    "    testing = path + \"dataTesting.zip\"\n",
    "\n",
    "    data_training = pd.read_csv(training, encoding='UTF-8', index_col=0)\n",
    "    data_testing = pd.read_csv(testing, encoding='UTF-8', index_col=0)\n",
    "\n",
    "    # Create the object\n",
    "    final_project = FinalProject(data_training, data_testing)\n",
    "\n",
    "    # Run the model\n",
    "    final_project.run(\n",
    "        epochs=30,\n",
    "        patience=5,\n",
    "        learning_rate=0.00001,\n",
    "        path=\"predictions.csv\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bde59a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
